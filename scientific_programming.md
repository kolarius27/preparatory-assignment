## Best Practices in Scientific Computing
Read the paper by Wilson et al. (2014) on Best Practices for Scientific Computing and answer the following questions. Write your answer in a Markdown file called scientific_programming.md. Read this Guide on markdown to format your file.

### 1. The paper describes several problems scientist face when performing scientific data analyses. From your experience in performing GIS and general data analyses, which of these problems seem familiar to you? Have you faced other problems not mentioned in the paper?

After reading this article (and also thanks to gaining more experience since the start of my "programming career", which was in autumn 2019) I've noticed multiple mistakes I do when I'm developing a script. A case example is definitely during writing my bachelor thesis. I was developing my own script to generate segmentation quality metrics from multiple results of Multiresolution segmentation (I was testing which parameters might be "the best" for specific input layers). The output of this script was a organized table with parameter combinations in rows and segmentation quality metrics (Oversegmentation, Undersegmentation...) in columns. I had a lack of time, so I used the methods and libraries I had been familiar with already (arcpy, csv module...). Because of that the script was really slow, because I was storing the values into lists of lists instead of using numpy or pandas. And that's just a start. The script as a whole was a mess, but the result was in the end the same as I was expecting, so I wasn't bothered with readability, reproducibility, replicability and other dilemmas. I see this course as an opportunity to avoid these mistakes in the future and to become more efficient programmer.

### 2. Which methods described in the paper or which other skills, tools etc. would you like to learn to help you avoid these problems in the future?

Many solutions to problems I had in the past were provided by the Geoscripting course, but many are yet to be solved. I'm almost never satisfied with my scripts because they seem to me unorganized and unstructured (it seemed to me almost every time as a "spaghetti model". Another my problem is that I get stuck with a problem that can be solved easily but sometimes I'm too stubborn to look for the solution online or in other libraries. What could definitely improve my programming skills is implementing assertions, automated testing and using profiler into my "scripting workflow". I have never used any debugger, I was always just using try-and-error rerunning and reading logs, which wasn't a really effiecient way of doing things.

### 3. One of the recommendations by Wilson et al. (2014) for scientists is to use a Version Control System (VCS). Briefly explain in your own words, what the benefits of VCS are in the context of scientific analyses.

Version Control System (VCS) is basically a "stenographic notation" of your code. It tracks down which changes were done in which commit/timestamp, so you have a complete history of your scripting progress. Everybody makes mistakes in his/her decisions, even scientists, thus scientist-programmer could come to a conclusion that his previous version of the script was better. With VCS he/she can easily pull his/her desired version from repository and continue with his/her work. Writing scripts is a very dynamic activity, where mistakes can be done really easily. Again, implementing VCS can improve efficiency, teamwork, reproducibility and other aspects of scientific analyses. 
